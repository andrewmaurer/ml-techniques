{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP with SpaCy\n",
    "\n",
    "I need to get more comfortable with the NLP pipeline, so I'm going to be experimenting with SpaCy and RNNs before starting a project based on these techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib: 3.1.0\n",
      "pandas: 0.24.2\n",
      "numpy: 1.16.4\n",
      "scipy: 1.3.0\n",
      "seaborn: 0.9.0\n",
      "spacy: 2.1.8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "\n",
    "import scipy as sp\n",
    "\n",
    "import json\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "pkgs = [matplotlib, pd, np, sp, sns, spacy]\n",
    "for pkg in pkgs:\n",
    "    print(f'{pkg.__name__}: {pkg.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model and Select Subset of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "\n",
    "with open('/home/amaurer/Documents/Data/yelp_dataset/review.json', 'r') as file:\n",
    "    for line in [file.readline() for x in range(100)]:\n",
    "        reviews.append(json.loads(line)['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total bill for this horrible service? Over $8Gs. These crooks actually had the nerve to charge us $69 for 3 pills. I checked online the pills can be had for 19 cents EACH! Avoid Hospital ERs at all costs. \n",
      "\n",
      "It's a giant Best Buy with 66 registers.  I don't get it.  What's the big deal about this place?? \n",
      "\n",
      "Hands down best Bloody Mary ever. So many things in my BM, veggies  mmm bacon.  \"Nailed it\" it's an appetizer. I also had the burger with fries. Who knew fries could be so good. The presentation doesn't disappoint ether. Very nice. Great seating outside although we sat inside. Would love to see this restaurant near my hometown. Seriously. Get the BM. You rock Guy! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in [0, 9, 99]:\n",
    "    print(reviews[i], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play Around With SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "docs = [nlp(review) for review in reviews]\n",
    "\n",
    "sample = docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total total\n",
      "bill bill\n",
      "for for\n",
      "this this\n",
      "horrible horrible\n",
      "service service\n",
      "? ?\n",
      "Over over\n",
      "$ $\n",
      "8Gs 8gs\n",
      ". .\n",
      "These these\n",
      "crooks crook\n",
      "actually actually\n",
      "had have\n",
      "the the\n",
      "nerve nerve\n",
      "to to\n",
      "charge charge\n",
      "us -PRON-\n",
      "$ $\n",
      "69 69\n",
      "for for\n",
      "3 3\n",
      "pills pill\n",
      ". .\n",
      "I -PRON-\n",
      "checked check\n",
      "online online\n",
      "the the\n",
      "pills pill\n",
      "can can\n",
      "be be\n",
      "had have\n",
      "for for\n",
      "19 19\n",
      "cents cent\n",
      "EACH EACH\n",
      "! !\n",
      "Avoid avoid\n",
      "Hospital hospital\n",
      "ERs er\n",
      "at at\n",
      "all all\n",
      "costs cost\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    \"Text\":[token.text for token in sample]\n",
    "    \"Lemma\":[token.lemma_ for token in samp]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp] *",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
